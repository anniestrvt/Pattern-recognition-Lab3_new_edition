{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anna/opt/anaconda2/envs/p36workshop/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['random']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from scipy.spatial import distance\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import random\n",
    "from xgboost import XGBClassifier\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images = list()\n",
    "    labels = list()\n",
    "    i = 0\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename !='.DS_Store':    \n",
    "            path = folder + \"/\" + filename\n",
    "            for cat in os.listdir(path):\n",
    "                img = cv2.imread(path + \"/\" + cat,0)\n",
    "                #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                if img is not None:\n",
    "                    images.append(img)\n",
    "                    labels.append(i)\n",
    "            i = i + 1\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_class(folder):\n",
    "    images = list()\n",
    "    for cat in os.listdir(folder):\n",
    "        img = cv2.imread(folder + \"/\" + cat,0)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    images_train, images_test = sklearn.model_selection.train_test_split(images, test_size = 50, random_state = 42)\n",
    "    return images_train, images_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptor_features(X):\n",
    "    descriptor_list = []\n",
    "    akaze = cv2.ORB_create()\n",
    "    for i in range(0, len(X)):\n",
    "        kp,des = akaze.detectAndCompute(X[i], None)\n",
    "        descriptor_list.extend(des)\n",
    "    return descriptor_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(k, descriptor_list):\n",
    "    kmeans = MiniBatchKMeans(n_clusters=k, n_init=10)\n",
    "    kmeans.fit(descriptor_list)\n",
    "    visual_words = kmeans.cluster_centers_\n",
    "    return visual_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_index(image, center):\n",
    "    count = 0\n",
    "    ind = 0\n",
    "    dist = 0\n",
    "    for i in range(len(center)):\n",
    "        if(i == 0):\n",
    "            count = distance.euclidean(image, center[i])\n",
    "            dist = count\n",
    "            #count = L1_dist(image, center[i])\n",
    "        else:\n",
    "            dist = distance.euclidean(image, center[i])\n",
    "            #dist = L1_dist(image, center[i])\n",
    "        if(dist < count):\n",
    "            ind = i\n",
    "            count = dist\n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_class(X, centers):\n",
    "    dict_feature = list()\n",
    "    akaze = cv2.ORB_create()\n",
    "    for i in range(0, len(X)):\n",
    "        #print(i)\n",
    "        kp,des = akaze.detectAndCompute(X[i], None)\n",
    "        histogram = np.zeros(len(centers))\n",
    "        for each_feature in des:\n",
    "            \n",
    "            ind = find_index(each_feature, centers)\n",
    "            histogram[ind] += 1\n",
    "        dict_feature.append(histogram)\n",
    "    return dict_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train = list()\n",
    "y_Train = list()\n",
    "X_Test = list()\n",
    "y_Test = list()\n",
    "filenames = ('True_Budda', 'True_parfum', 'False')\n",
    "for i in range(0, 3):\n",
    "    x1, x2 = load_images_class('Photos/'+filenames[i])\n",
    "    X_Train.extend(x1)\n",
    "    X_Test.extend(x2)\n",
    "    for j in range(0, len(x1)):\n",
    "        y_Train.append(i)\n",
    "    for j in range(0, len(x2)):\n",
    "        y_Test.append(i)\n",
    "X_train, y_train = sklearn.utils.shuffle(X_Train, y_Train, random_state = 42)\n",
    "X_test, y_test = sklearn.utils.shuffle(X_Test, y_Test, random_state = 42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors = descriptor_features(X_train)\n",
    "words = kmeans(200, descriptors)\n",
    "X_train_new = image_class(X_train, words)\n",
    "X_test_new = image_class(X_test, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "парфюм = 1, Будда = 0, мусор = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функція для знаходження статистики по кожному методу "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y1, y2):\n",
    "    S = 0\n",
    "    for i in range(0, len(y1)):\n",
    "        if y1[i]==y2[i]:\n",
    "            S = S + 1\n",
    "    S = S/len(y1)\n",
    "    print(\"Accuracy: \" + str(S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_matrix(y_test, y_pred):\n",
    "    matrix = np.zeros((3, 3))\n",
    "    for i in range(0, len(y_test)):\n",
    "        a = y_test[i]\n",
    "        b = y_pred[i]\n",
    "        matrix[a][b]= matrix[a][b] + 1\n",
    "    print(\"Confusion matrix\\n\")\n",
    "    print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вибір класифікатора без підбору параметрів"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градієнтний бустінг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5266666666666666\n",
      "Confusion matrix\n",
      "\n",
      "[[36. 13.  1.]\n",
      " [12. 37.  1.]\n",
      " [26. 18.  6.]]\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "model.fit(X_train_new, y_train)\n",
    "y_pred = model.predict(X_test_new)\n",
    "accuracy(y_test, y_pred)\n",
    "conf_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Випадковий ліс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n",
      "Confusion matrix\n",
      "\n",
      "[[38. 12.  0.]\n",
      " [14. 36.  0.]\n",
      " [35. 14.  1.]]\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(X_train_new, y_train)\n",
    "y_pred = model.predict(X_test_new)\n",
    "accuracy(y_test, y_pred)\n",
    "conf_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дерево прийняття рішень"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4266666666666667\n",
      "Confusion matrix\n",
      "\n",
      "[[29. 15.  6.]\n",
      " [18. 28.  4.]\n",
      " [26. 17.  7.]]\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train_new, y_train)\n",
    "y_pred = model.predict(X_test_new)\n",
    "accuracy(y_test, y_pred)\n",
    "conf_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.52\n",
      "Confusion matrix\n",
      "\n",
      "[[32. 14.  4.]\n",
      " [ 8. 39.  3.]\n",
      " [30. 13.  7.]]\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "arr = np.array(y_train)\n",
    "arr1 = np.array(X_train_new)\n",
    "arr2 = np.array(X_test_new)\n",
    "model.fit(arr1, arr)\n",
    "y_pred = model.predict(arr2)\n",
    "accuracy(y_test, y_pred)\n",
    "conf_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Підбір параметрів для кожного з методів за допомогою GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=GradientBoostingClassifier(),\n",
       "             param_grid={'max_depth': (3, 5, 8), 'min_samples_leaf': (1, 3, 4),\n",
       "                         'min_samples_split': (2, 4, 6),\n",
       "                         'n_estimators': (100, 150)},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'min_samples_split':(2,4, 6), \n",
    "              'min_samples_leaf':(1, 3,4), \n",
    "              'max_depth':(3,5,8),\n",
    "             'n_estimators':(100, 150)}\n",
    "m = GradientBoostingClassifier()\n",
    "model1 = GridSearchCV(m, parameters, return_train_score = True)\n",
    "model1.fit(X_train_new, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n",
      "Confusion matrix\n",
      "\n",
      "[[31. 15.  4.]\n",
      " [ 8. 39.  3.]\n",
      " [26. 19.  5.]]\n",
      "CPU times: user 5.39 ms, sys: 264 µs, total: 5.66 ms\n",
      "Wall time: 5.72 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = model1.predict(X_test_new)\n",
    "accuracy(y_test, y_pred)\n",
    "conf_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5,\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 6,\n",
       " 'n_estimators': 150}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6929125138427464"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'n_estimators':(100,125, 150), \n",
    "              'min_samples_split':(2, 4, 3),\n",
    "             'min_samples_leaf':(1, 3, 5)}\n",
    "m = RandomForestClassifier()\n",
    "model2 = GridSearchCV(m, parameters, return_train_score = True)\n",
    "model2.fit(X_train_new, y_train)\n",
    "y_pred = model2.predict(X_test_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4866666666666667\n",
      "Confusion matrix\n",
      "\n",
      "[[35. 14.  1.]\n",
      " [12. 38.  0.]\n",
      " [36. 14.  0.]]\n",
      "CPU times: user 20.6 ms, sys: 2.66 ms, total: 23.2 ms\n",
      "Wall time: 23.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = model2.predict(X_test_new)\n",
    "accuracy(y_test, y_pred)\n",
    "conf_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_leaf': 3, 'min_samples_split': 4, 'n_estimators': 125}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.683610188261351"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'criterion': ('gini', 'entropy'),\n",
       "                         'min_samples_leaf': (1, 3, 4),\n",
       "                         'min_samples_split': (2, 4, 6),\n",
       "                         'splitter': ('best', 'random')},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'splitter':('best', 'random'),\n",
    "              'min_samples_split':(2, 4, 6),\n",
    "              'min_samples_leaf':(1, 3, 4),\n",
    "              'criterion':('gini', 'entropy')}\n",
    "m = DecisionTreeClassifier()\n",
    "model3 = GridSearchCV(m, parameters, return_train_score = True)\n",
    "model3.fit(X_train_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4\n",
      "Confusion matrix\n",
      "\n",
      "[[28. 17.  5.]\n",
      " [21. 27.  2.]\n",
      " [26. 19.  5.]]\n",
      "CPU times: user 1.85 ms, sys: 699 µs, total: 2.54 ms\n",
      "Wall time: 2.54 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = model3.predict(X_test_new)\n",
    "accuracy(y_test, y_pred)\n",
    "conf_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 2,\n",
       " 'splitter': 'random'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6269102990033224"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None...\n",
       "                                     reg_alpha=None, reg_lambda=None,\n",
       "                                     scale_pos_weight=None, subsample=None,\n",
       "                                     tree_method=None, validate_parameters=None,\n",
       "                                     verbosity=None),\n",
       "             param_grid={'colsample_bytree': [0.5, 0.7],\n",
       "                         'learning_rate': [0.01, 0.1],\n",
       "                         'max_depth': [3, 5, 7, 10],\n",
       "                         'min_child_weight': [1, 3, 5],\n",
       "                         'n_estimators': [100, 200, 500],\n",
       "                         'objective': ['reg:squarederror'],\n",
       "                         'subsample': [0.5, 0.7]},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'max_depth': [3, 5, 7, 10],\n",
    "        'min_child_weight': [1, 3, 5],\n",
    "        'subsample': [0.5, 0.7],\n",
    "        'colsample_bytree': [0.5, 0.7],\n",
    "        'n_estimators' : [100, 200, 500],\n",
    "        'objective': ['reg:squarederror']\n",
    "    }\n",
    "m = XGBClassifier()\n",
    "model4 = GridSearchCV(m, parameters, return_train_score = True)\n",
    "arr = np.array(y_train)\n",
    "arr1 = np.array(X_train_new)\n",
    "arr2 = np.array(X_test_new)\n",
    "model4.fit(arr1, arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5666666666666667\n",
      "Confusion matrix\n",
      "\n",
      "[[38. 12.  0.]\n",
      " [10. 40.  0.]\n",
      " [32. 11.  7.]]\n",
      "CPU times: user 19.2 ms, sys: 3.06 ms, total: 22.3 ms\n",
      "Wall time: 18.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = model4.predict(arr2)\n",
    "accuracy(y_test, y_pred)\n",
    "conf_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.5,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 10,\n",
       " 'min_child_weight': 1,\n",
       " 'n_estimators': 500,\n",
       " 'objective': 'reg:squarederror',\n",
       " 'subsample': 0.7}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6930232558139535"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Робота з відео"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "За длпомогою OpenCV обробимо 2 коротеньких відео, на яких є один чи інший об'єкт, застосовуючи до кожного 5го кадру кожну з моделей; бедмо писати поверх кадру в кожний момент, який саме об'єкт був знайдений і чи був знайдений взагалі. В результаті отримуємо 8 відео"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_video(file_name_read, file_name_write):\n",
    "    cap1 = cv2.VideoCapture(file_name_read)\n",
    "    frame_width = int(cap1.get(3))\n",
    "    frame_height = int(cap1.get(4))\n",
    "    out = cv2.VideoWriter(file_name_write,cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame_width,frame_height))\n",
    "    #set method here\n",
    "    # and don't forget to use appropriate model\n",
    "    akaze = cv2.ORB_create()\n",
    "    # features for text\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "    org = (50, 50) \n",
    "    fontScale = 1\n",
    "    color = (255, 0, 0) \n",
    "    thickness = 2\n",
    "    i = 0\n",
    "    while cap1.isOpened():\n",
    "        ret, frame = cap1.read() \n",
    "        if not ret:\n",
    "            break\n",
    "        if i%5 == 0:\n",
    "            kp,des = akaze.detectAndCompute(frame, None)\n",
    "            histogram = np.zeros(len(words))\n",
    "            for each_feature in des:\n",
    "                ind = find_index(each_feature, words)\n",
    "                histogram[ind] += 1\n",
    "            histogram = histogram.reshape(1, -1)\n",
    "            # трошки криво, тут вручну вказує номер моделі з якою працюємо\n",
    "            y_pred = model4.predict(histogram)\n",
    "            if y_pred == 1:\n",
    "                frame = cv2.putText(frame, 'Parfum', org, font,fontScale, color, thickness, cv2.LINE_AA)\n",
    "            if y_pred == 0:\n",
    "                frame = cv2.putText(frame, 'Budda', org, font,fontScale, color, thickness, cv2.LINE_AA)\n",
    "            if y_pred == 2:\n",
    "                frame = cv2.putText(frame, 'Nothing', org, font,fontScale, color, thickness, cv2.LINE_AA)\n",
    "            out.write(frame)\n",
    "        i = i+1\n",
    "    cap1.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_video('/Users/anna/detection/Lab3/video.mp4', 'Videos/orb_video1_gradient_boosting.avi')\n",
    "#create_video('/Users/anna/detection/video2.mp4', 'Videos/orb_video2_gradient_boosting.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_video('/Users/anna/detection/Lab3/video.mp4', 'Videos/orb_video1_random_forest.avi')\n",
    "#create_video('/Users/anna/detection/video2.mp4', 'Videos/orb_video2_random_forest.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_video('/Users/anna/detection/Lab3/video.mp4', 'Videos/orb_video1_decision_tree.avi')\n",
    "#create_video('/Users/anna/detection/video2.mp4', 'Videos/orb_video2_decision_tree.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_video('/Users/anna/detection/Lab3/video.mp4', 'Videos/orb_video1_xgboost.avi')\n",
    "#create_video('/Users/anna/detection/video2.mp4', 'Videos/orb_video2_xgboost.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p36workshop",
   "language": "python",
   "name": "p36workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
