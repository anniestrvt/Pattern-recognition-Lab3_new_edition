{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anna/opt/anaconda2/envs/p36workshop/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['random']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from scipy.spatial import distance\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import random\n",
    "from xgboost import XGBClassifier\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images = list()\n",
    "    labels = list()\n",
    "    i = 0\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename !='.DS_Store':    \n",
    "            path = folder + \"/\" + filename\n",
    "            for cat in os.listdir(path):\n",
    "                img = cv2.imread(path + \"/\" + cat,0)\n",
    "                #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                if img is not None:\n",
    "                    images.append(img)\n",
    "                    labels.append(i)\n",
    "            i = i + 1\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_class(folder):\n",
    "    images = list()\n",
    "    for cat in os.listdir(folder):\n",
    "        img = cv2.imread(folder + \"/\" + cat,0)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    images_train, images_test = sklearn.model_selection.train_test_split(images, test_size = 50, random_state = 42)\n",
    "    return images_train, images_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptor_features(X):\n",
    "    descriptor_list = []\n",
    "    akaze = cv2.AKAZE_create()\n",
    "    for i in range(0, len(X)):\n",
    "        kp,des = akaze.detectAndCompute(X[i], None)\n",
    "        descriptor_list.extend(des)\n",
    "    return descriptor_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(k, descriptor_list):\n",
    "    kmeans = MiniBatchKMeans(n_clusters=k, n_init=10)\n",
    "    kmeans.fit(descriptor_list)\n",
    "    visual_words = kmeans.cluster_centers_\n",
    "    return visual_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_index(image, center):\n",
    "    count = 0\n",
    "    ind = 0\n",
    "    dist = 0\n",
    "    for i in range(len(center)):\n",
    "        if(i == 0):\n",
    "            count = distance.euclidean(image, center[i])\n",
    "            dist = count\n",
    "            #count = L1_dist(image, center[i])\n",
    "        else:\n",
    "            dist = distance.euclidean(image, center[i])\n",
    "            #dist = L1_dist(image, center[i])\n",
    "        if(dist < count):\n",
    "            ind = i\n",
    "            count = dist\n",
    "    return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_class(X, centers):\n",
    "    dict_feature = list()\n",
    "    akaze = cv2.AKAZE_create()\n",
    "    for i in range(0, len(X)):\n",
    "        #print(i)\n",
    "        kp,des = akaze.detectAndCompute(X[i], None)\n",
    "        histogram = np.zeros(len(centers))\n",
    "        for each_feature in des:\n",
    "            \n",
    "            ind = find_index(each_feature, centers)\n",
    "            histogram[ind] += 1\n",
    "        dict_feature.append(histogram)\n",
    "    return dict_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train = list()\n",
    "y_Train = list()\n",
    "X_Test = list()\n",
    "y_Test = list()\n",
    "filenames = ('True_Budda', 'True_parfum', 'False')\n",
    "for i in range(0, 3):\n",
    "    x1, x2 = load_images_class('Photos/'+filenames[i])\n",
    "    X_Train.extend(x1)\n",
    "    X_Test.extend(x2)\n",
    "    for j in range(0, len(x1)):\n",
    "        y_Train.append(i)\n",
    "    for j in range(0, len(x2)):\n",
    "        y_Test.append(i)\n",
    "X_train, y_train = sklearn.utils.shuffle(X_Train, y_Train, random_state = 42)\n",
    "X_test, y_test = sklearn.utils.shuffle(X_Test, y_Test, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors = descriptor_features(X_train)\n",
    "words = kmeans(200, descriptors)\n",
    "X_train_new = image_class(X_train, words)\n",
    "X_test_new = image_class(X_test, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "парфум = 1, Буда = 0, нічого = 2( class labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функція для знаходження статистики по кожному методу "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y1, y2):\n",
    "    S = 0\n",
    "    for i in range(0, len(y1)):\n",
    "        if y1[i]==y2[i]:\n",
    "            S = S + 1\n",
    "    S = S/len(y1)\n",
    "    print(\"Accuracy: \" + str(S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_matrix(y_test, y_pred):\n",
    "    matrix = np.zeros((3, 3))\n",
    "    for i in range(0, len(y_test)):\n",
    "        a = y_test[i]\n",
    "        b = y_pred[i]\n",
    "        matrix[a][b]= matrix[a][b] + 1\n",
    "    print(\"Confusion matrix\\n\")\n",
    "    print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вибір класифікатора без підбору параметрів"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градієнтний бустінг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5866666666666667\n",
      "Confusion matrix\n",
      "\n",
      "[[40.  4.  6.]\n",
      " [ 7. 43.  0.]\n",
      " [24. 21.  5.]]\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "model.fit(X_train_new, y_train)\n",
    "y_pred = model.predict(X_test_new)\n",
    "accuracy(y_test, y_pred)\n",
    "conf_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Випадковий ліс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.58\n",
      "Confusion matrix\n",
      "\n",
      "[[41.  8.  1.]\n",
      " [ 6. 42.  2.]\n",
      " [26. 20.  4.]]\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(X_train_new, y_train)\n",
    "y_pred = model.predict(X_test_new)\n",
    "accuracy(y_test, y_pred)\n",
    "conf_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дерево прийняття рішень"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.52\n",
      "Confusion matrix\n",
      "\n",
      "[[31.  8. 11.]\n",
      " [12. 36.  2.]\n",
      " [24. 15. 11.]]\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train_new, y_train)\n",
    "y_pred = model.predict(X_test_new)\n",
    "accuracy(y_test, y_pred)\n",
    "conf_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5933333333333334\n",
      "Confusion matrix\n",
      "\n",
      "[[40.  5.  5.]\n",
      " [ 8. 42.  0.]\n",
      " [25. 18.  7.]]\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "arr = np.array(y_train)\n",
    "arr1 = np.array(X_train_new)\n",
    "arr2 = np.array(X_test_new)\n",
    "model.fit(arr1, arr)\n",
    "y_pred = model.predict(arr2)\n",
    "accuracy(y_test, y_pred)\n",
    "conf_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Підбір параметрів для кожного з методів за допомогою GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=GradientBoostingClassifier(),\n",
       "             param_grid={'max_depth': (3, 5, 8), 'min_samples_leaf': (1, 3, 4),\n",
       "                         'min_samples_split': (2, 4, 6),\n",
       "                         'n_estimators': (100, 150)},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'min_samples_split':(2,4, 6), \n",
    "              'min_samples_leaf':(1, 3,4), \n",
    "              'max_depth':(3,5,8),\n",
    "             'n_estimators':(100, 150)}\n",
    "m = GradientBoostingClassifier()\n",
    "model1 = GridSearchCV(m, parameters, return_train_score = True)\n",
    "model1.fit(X_train_new, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6066666666666667\n",
      "Confusion matrix\n",
      "\n",
      "[[42.  6.  2.]\n",
      " [ 8. 39.  3.]\n",
      " [22. 18. 10.]]\n",
      "CPU times: user 7.85 ms, sys: 1.92 ms, total: 9.76 ms\n",
      "Wall time: 8.94 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = model1.predict(X_test_new)\n",
    "accuracy(y_test, y_pred)\n",
    "conf_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 8,\n",
       " 'min_samples_leaf': 3,\n",
       " 'min_samples_split': 6,\n",
       " 'n_estimators': 150}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6792912513842746"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'n_estimators':(100,125, 150), \n",
    "              'min_samples_split':(2, 4, 3),\n",
    "             'min_samples_leaf':(1, 3, 5)}\n",
    "m = RandomForestClassifier()\n",
    "model2 = GridSearchCV(m, parameters, return_train_score = True)\n",
    "model2.fit(X_train_new, y_train)\n",
    "y_pred = model2.predict(X_test_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5866666666666667\n",
      "Confusion matrix\n",
      "\n",
      "[[42.  8.  0.]\n",
      " [ 4. 45.  1.]\n",
      " [26. 23.  1.]]\n",
      "CPU times: user 15.2 ms, sys: 2.14 ms, total: 17.4 ms\n",
      "Wall time: 15.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = model2.predict(X_test_new)\n",
    "accuracy(y_test, y_pred)\n",
    "conf_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 100}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.726578073089701"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'criterion': ('gini', 'entropy'),\n",
       "                         'min_samples_leaf': (1, 3, 4),\n",
       "                         'min_samples_split': (2, 4, 6),\n",
       "                         'splitter': ('best', 'random')},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'splitter':('best', 'random'),\n",
    "              'min_samples_split':(2, 4, 6),\n",
    "              'min_samples_leaf':(1, 3, 4),\n",
    "              'criterion':('gini', 'entropy')}\n",
    "m = DecisionTreeClassifier()\n",
    "model3 = GridSearchCV(m, parameters, return_train_score = True)\n",
    "model3.fit(X_train_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4666666666666667\n",
      "Confusion matrix\n",
      "\n",
      "[[36.  7.  7.]\n",
      " [14. 28.  8.]\n",
      " [25. 19.  6.]]\n",
      "CPU times: user 2.14 ms, sys: 1.41 ms, total: 3.55 ms\n",
      "Wall time: 2.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = model3.predict(X_test_new)\n",
    "accuracy(y_test, y_pred)\n",
    "conf_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'min_samples_leaf': 3,\n",
       " 'min_samples_split': 6,\n",
       " 'splitter': 'random'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6085271317829457"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None...\n",
       "                                     reg_alpha=None, reg_lambda=None,\n",
       "                                     scale_pos_weight=None, subsample=None,\n",
       "                                     tree_method=None, validate_parameters=None,\n",
       "                                     verbosity=None),\n",
       "             param_grid={'colsample_bytree': [0.5, 0.7],\n",
       "                         'learning_rate': [0.01, 0.1],\n",
       "                         'max_depth': [3, 5, 7, 10],\n",
       "                         'min_child_weight': [1, 3, 5],\n",
       "                         'n_estimators': [100, 200, 500],\n",
       "                         'objective': ['reg:squarederror'],\n",
       "                         'subsample': [0.5, 0.7]},\n",
       "             return_train_score=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'max_depth': [3, 5, 7, 10],\n",
    "        'min_child_weight': [1, 3, 5],\n",
    "        'subsample': [0.5, 0.7],\n",
    "        'colsample_bytree': [0.5, 0.7],\n",
    "        'n_estimators' : [100, 200, 500],\n",
    "        'objective': ['reg:squarederror']\n",
    "    }\n",
    "m = XGBClassifier()\n",
    "model4 = GridSearchCV(m, parameters, return_train_score = True)\n",
    "arr = np.array(y_train)\n",
    "arr1 = np.array(X_train_new)\n",
    "arr2 = np.array(X_test_new)\n",
    "model4.fit(arr1, arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6133333333333333\n",
      "Confusion matrix\n",
      "\n",
      "[[42.  6.  2.]\n",
      " [ 4. 44.  2.]\n",
      " [24. 20.  6.]]\n",
      "CPU times: user 11.4 ms, sys: 1.98 ms, total: 13.4 ms\n",
      "Wall time: 14.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = model4.predict(arr2)\n",
    "accuracy(y_test, y_pred)\n",
    "conf_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.5,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 5,\n",
       " 'min_child_weight': 3,\n",
       " 'n_estimators': 500,\n",
       " 'objective': 'reg:squarederror',\n",
       " 'subsample': 0.5}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7313399778516058"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Робота з відео"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "За допомогою OpenCV обробимо 2 коротеньких відео, на яких є один чи інший об'єкт, застосовуючи до кожного 5го кадру кожну з моделей; бедмо писати поверх кадру в кожний момент, який саме об'єкт був знайдений і чи був знайдений взагалі. В результаті отримуємо 8 відео"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_video(file_name_read, file_name_write):\n",
    "    cap1 = cv2.VideoCapture(file_name_read)\n",
    "    frame_width = int(cap1.get(3))\n",
    "    frame_height = int(cap1.get(4))\n",
    "    out = cv2.VideoWriter(file_name_write,cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame_width,frame_height))\n",
    "    #set method here\n",
    "    # and don't forget to use appropriate model\n",
    "    akaze = cv2.AKAZE_create()\n",
    "    # features for text\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "    org = (50, 50) \n",
    "    fontScale = 1\n",
    "    color = (255, 0, 0) \n",
    "    thickness = 2\n",
    "    i = 0\n",
    "    while cap1.isOpened():\n",
    "        ret, frame = cap1.read() \n",
    "        if not ret:\n",
    "            break\n",
    "        if i%5 == 0:\n",
    "            kp,des = akaze.detectAndCompute(frame, None)\n",
    "            histogram = np.zeros(len(words))\n",
    "            for each_feature in des:\n",
    "                ind = find_index(each_feature, words)\n",
    "                histogram[ind] += 1\n",
    "            histogram = histogram.reshape(1, -1)\n",
    "            # трошки криво, тут вручну вказує номер моделі з якою працюємо\n",
    "            y_pred = model4.predict(histogram)\n",
    "            if y_pred == 1:\n",
    "                frame = cv2.putText(frame, 'Parfum', org, font,fontScale, color, thickness, cv2.LINE_AA)\n",
    "            if y_pred == 0:\n",
    "                frame = cv2.putText(frame, 'Budda', org, font,fontScale, color, thickness, cv2.LINE_AA)\n",
    "            if y_pred == 2:\n",
    "                frame = cv2.putText(frame, 'Nothing', org, font,fontScale, color, thickness, cv2.LINE_AA)\n",
    "            out.write(frame)\n",
    "        i = i+1\n",
    "    cap1.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_video('/Users/anna/detection/Lab3/video.mp4', 'Videos/akaze_video1_gradient_boosting.avi')\n",
    "#create_video('/Users/anna/detection/video2.mp4', 'Videos/akaze_video2_gradient_boosting.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_video('/Users/anna/detection/Lab3/video.mp4', 'Videos/akaze_video1_random_forest.avi')\n",
    "#create_video('/Users/anna/detection/video2.mp4', 'Videos/akaze_video2_random_forest.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_video('/Users/anna/detection/Lab3/video.mp4', 'Videos/akaze_video1_decision_tree.avi')\n",
    "#create_video('/Users/anna/detection/video2.mp4', 'Videos/akaze_video2_decision_tree.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_video('/Users/anna/detection/Lab3/video.mp4', 'Videos/akaze_video1_xgboost.avi')\n",
    "#create_video('/Users/anna/detection/video2.mp4', 'Videos/akaze_video2_xgboost.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p36workshop",
   "language": "python",
   "name": "p36workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
